{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Learning MLPipelines using spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Example for writing functions that handles errors. We use this function to\n",
    "##convert each element of the row to double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39.0, u'State-gov', 77516.0, u'Bachelors', 13.0, u'Never-married', u'Adm-clerical', u'Not-in-family', u'White', u'Male', 2174.0, 0.0, 40.0, u'United-States', u'<=50K']]\n"
     ]
    }
   ],
   "source": [
    "rawData = (sc.textFile(path)\n",
    "           .map(lambda x : x.split(\",\"))\n",
    "           .map(lambda l : map(lambda element: typeConvert(element),l))\n",
    "           .take(1)\n",
    "            )\n",
    "print rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def typeConvert(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError,TypeError:\n",
    "        return (value.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.0,\n",
       " u'State-gov',\n",
       " 77516.0,\n",
       " u'Bachelors',\n",
       " 13.0,\n",
       " u'Never-married',\n",
       " u'Adm-clerical',\n",
       " u'Not-in-family',\n",
       " u'White',\n",
       " u'Male',\n",
       " 2174.0,\n",
       " 0.0,\n",
       " 40.0,\n",
       " u'United-States',\n",
       " u'<=50K']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/vishnu/Documents/datasets/myexperiments/adult/adult.data'\n",
    "rawData = (sc.textFile(path)\n",
    "           .map(lambda x : x.split(\",\"))\n",
    "           .map(lambda l : map(lambda element: typeConvert(element),l))\n",
    "            )\n",
    "    \n",
    "rawData.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newRawData = (sc.textFile(path)\n",
    "           .map(lambda x : x.split(\",\"))\n",
    "           .map(lambda x : len(x))\n",
    "           .distinct()\n",
    "           .collect()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 15]\n"
     ]
    }
   ],
   "source": [
    "print newRawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'']]\n"
     ]
    }
   ],
   "source": [
    "newRawData = (sc.textFile(path)\n",
    "           .map(lambda x : x.split(\",\"))\n",
    "           .filter(lambda x : len(x)==1)\n",
    "            .take(10) )\n",
    "print newRawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = (sc.textFile(path)\n",
    "           .map(lambda x : x.split(\",\"))\n",
    "           .filter(lambda x : len(x)==15)\n",
    "           .map(lambda l : map(lambda element: typeConvert(element),l))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.0,\n",
       " u'State-gov',\n",
       " 77516.0,\n",
       " u'Bachelors',\n",
       " 13.0,\n",
       " u'Never-married',\n",
       " u'Adm-clerical',\n",
       " u'Not-in-family',\n",
       " u'White',\n",
       " u'Male',\n",
       " 2174.0,\n",
       " 0.0,\n",
       " 40.0,\n",
       " u'United-States',\n",
       " u'<=50K']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType ,DoubleType ,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"age\",FloatType(),True),\n",
    "    StructField(\"workclass\",StringType(),True),\n",
    "    StructField(\"fnlwgt\",DoubleType(),True),\n",
    "    StructField(\"education\",StringType(),True),\n",
    "    StructField(\"unknown\",StringType(),True),  \n",
    "    StructField(\"marital_status\",StringType(),True),\n",
    "    StructField(\"occupation\",StringType(),True),\n",
    "    StructField(\"relationship\",StringType(),True),\n",
    "    StructField(\"race\",StringType(),True),\n",
    "    StructField(\"sex\",StringType(),True),\n",
    "    StructField(\"capital_gain\",DoubleType(),True),\n",
    "    StructField(\"capital_loss\",DoubleType(),True),\n",
    "    StructField(\"hours_per_week\",DoubleType(),True),\n",
    "    StructField(\"native_country\",StringType(),True),\n",
    "    StructField(\"income\",StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Create a DataFrame by applying the schema to the RDD and print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawdf = sqlContext.createDataFrame(rawData, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- unknown: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdf = rawdf.drop('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|       workclass|count|\n",
      "+----------------+-----+\n",
      "|         Private|24532|\n",
      "|     Federal-gov|  960|\n",
      "|       State-gov| 1298|\n",
      "|       Local-gov| 2093|\n",
      "|    Self-emp-inc| 1116|\n",
      "|     Without-pay|   14|\n",
      "|    Never-worked|    7|\n",
      "|Self-emp-not-inc| 2541|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rawdf.groupBy(\"workclass\").count().show()\n",
    "rawdf.groupBy(\"workclass\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|    native_country|count|\n",
      "+------------------+-----+\n",
      "|     United-States|29170|\n",
      "|            Mexico|  643|\n",
      "|           Private|  583|\n",
      "|       Philippines|  198|\n",
      "|           Germany|  137|\n",
      "|            Canada|  121|\n",
      "|       Puerto-Rico|  114|\n",
      "|       El-Salvador|  106|\n",
      "|             India|  100|\n",
      "|              Cuba|   95|\n",
      "|           England|   90|\n",
      "|           Jamaica|   81|\n",
      "|             South|   80|\n",
      "|             China|   75|\n",
      "|             Italy|   73|\n",
      "|Dominican-Republic|   70|\n",
      "|           Vietnam|   67|\n",
      "|         Guatemala|   64|\n",
      "|             Japan|   62|\n",
      "|            Poland|   60|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "rawdf.groupBy(\"native_country\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|occupation       |count|\n",
      "+-----------------+-----+\n",
      "|Other-service    |3295 |\n",
      "|Prof-specialty   |4140 |\n",
      "|Farming-fishing  |994  |\n",
      "|?                |1843 |\n",
      "|Protective-serv  |649  |\n",
      "|Adm-clerical     |3770 |\n",
      "|Machine-op-inspct|2002 |\n",
      "|Transport-moving |1597 |\n",
      "|Sales            |3650 |\n",
      "|Priv-house-serv  |149  |\n",
      "|Handlers-cleaners|1370 |\n",
      "|Craft-repair     |4099 |\n",
      "|Exec-managerial  |4066 |\n",
      "|Tech-support     |928  |\n",
      "|Armed-Forces     |9    |\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawdf.groupBy(\"occupation\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawdf = rawdf.na.replace(['?'],['Private'],'workclass')\n",
    "rawdf = rawdf.na.replace(['?'],['Private'],'native_country')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|       workclass|count|\n",
      "+----------------+-----+\n",
      "|         Private|24532|\n",
      "|     Federal-gov|  960|\n",
      "|       State-gov| 1298|\n",
      "|       Local-gov| 2093|\n",
      "|    Self-emp-inc| 1116|\n",
      "|     Without-pay|   14|\n",
      "|    Never-worked|    7|\n",
      "|Self-emp-not-inc| 2541|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawdf.groupBy(\"workclass\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|    native_country|count|\n",
      "+------------------+-----+\n",
      "|     United-States|29170|\n",
      "|            Mexico|  643|\n",
      "|           Private|  583|\n",
      "|       Philippines|  198|\n",
      "|           Germany|  137|\n",
      "|            Canada|  121|\n",
      "|       Puerto-Rico|  114|\n",
      "|       El-Salvador|  106|\n",
      "|             India|  100|\n",
      "|              Cuba|   95|\n",
      "|           England|   90|\n",
      "|           Jamaica|   81|\n",
      "|             South|   80|\n",
      "|             China|   75|\n",
      "|             Italy|   73|\n",
      "|Dominican-Republic|   70|\n",
      "|           Vietnam|   67|\n",
      "|         Guatemala|   64|\n",
      "|             Japan|   62|\n",
      "|            Poland|   60|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawdf.groupBy(\"native_country\").count().orderBy(\"count\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "def indexStringColumns(df,cols):\n",
    "    tempdf = df\n",
    "    for col in cols:\n",
    "        stringIndexer = StringIndexer(inputCol=col,outputCol=col+\"-num\")\n",
    "        si_model = stringIndexer.fit(tempdf)\n",
    "        tempdf = si_model.transform(tempdf).drop(col)\n",
    "        tempdf = tempdf.withColumnRenamed(col+\"-num\",col)\n",
    "    return tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['native_country', 'relationship', 'marital_status', 'sex', 'race', 'income', 'workclass', 'education', 'occupation'])\n",
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: double (nullable = true)\n",
      " |-- relationship: double (nullable = true)\n",
      " |-- marital_status: double (nullable = true)\n",
      " |-- sex: double (nullable = true)\n",
      " |-- race: double (nullable = true)\n",
      " |-- income: double (nullable = true)\n",
      " |-- workclass: double (nullable = true)\n",
      " |-- education: double (nullable = true)\n",
      " |-- occupation: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = {\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"income\"}\n",
    "dfnumeric = indexStringColumns(rawdf,cols)\n",
    "print cols\n",
    "dummy.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+-----------------+-------------+------------------+------+--------------+------+\n",
      "|       workclass|   education|      marital_status|       occupation| relationship|              race|   sex|native_country|income|\n",
      "+----------------+------------+--------------------+-----------------+-------------+------------------+------+--------------+------+\n",
      "|       State-gov|   Bachelors|       Never-married|     Adm-clerical|Not-in-family|             White|  Male| United-States| <=50K|\n",
      "|Self-emp-not-inc|   Bachelors|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male| United-States| <=50K|\n",
      "|         Private|     HS-grad|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male| United-States| <=50K|\n",
      "|         Private|        11th|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male| United-States| <=50K|\n",
      "|         Private|   Bachelors|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|          Cuba| <=50K|\n",
      "|         Private|     Masters|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female| United-States| <=50K|\n",
      "|         Private|         9th|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|       Jamaica| <=50K|\n",
      "|Self-emp-not-inc|     HS-grad|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male| United-States|  >50K|\n",
      "|         Private|     Masters|       Never-married|   Prof-specialty|Not-in-family|             White|Female| United-States|  >50K|\n",
      "|         Private|   Bachelors|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male| United-States|  >50K|\n",
      "|         Private|Some-college|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male| United-States|  >50K|\n",
      "|       State-gov|   Bachelors|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|         India|  >50K|\n",
      "|         Private|   Bachelors|       Never-married|     Adm-clerical|    Own-child|             White|Female| United-States| <=50K|\n",
      "|         Private|  Assoc-acdm|       Never-married|            Sales|Not-in-family|             Black|  Male| United-States| <=50K|\n",
      "|         Private|   Assoc-voc|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|       Private|  >50K|\n",
      "|         Private|     7th-8th|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|        Mexico| <=50K|\n",
      "|Self-emp-not-inc|     HS-grad|       Never-married|  Farming-fishing|    Own-child|             White|  Male| United-States| <=50K|\n",
      "|         Private|     HS-grad|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male| United-States| <=50K|\n",
      "|         Private|        11th|  Married-civ-spouse|            Sales|      Husband|             White|  Male| United-States| <=50K|\n",
      "|Self-emp-not-inc|     Masters|            Divorced|  Exec-managerial|    Unmarried|             White|Female| United-States|  >50K|\n",
      "+----------------+------------+--------------------+-----------------+-------------+------------------+------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(rawdf.select(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"income\")\n",
    "      .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+----------+------------+----+---+--------------+------+\n",
      "|workclass|education|marital_status|occupation|relationship|race|sex|native_country|income|\n",
      "+---------+---------+--------------+----------+------------+----+---+--------------+------+\n",
      "|      3.0|      2.0|           1.0|       3.0|         1.0| 0.0|0.0|           0.0|   0.0|\n",
      "|      1.0|      2.0|           0.0|       2.0|         0.0| 0.0|0.0|           0.0|   0.0|\n",
      "|      0.0|      0.0|           2.0|       9.0|         1.0| 0.0|0.0|           0.0|   0.0|\n",
      "|      0.0|      5.0|           0.0|       9.0|         0.0| 1.0|0.0|           0.0|   0.0|\n",
      "|      0.0|      2.0|           0.0|       0.0|         4.0| 1.0|1.0|           9.0|   0.0|\n",
      "|      0.0|      3.0|           0.0|       2.0|         4.0| 0.0|1.0|           0.0|   0.0|\n",
      "|      0.0|     10.0|           5.0|       5.0|         1.0| 1.0|1.0|          11.0|   0.0|\n",
      "|      1.0|      0.0|           0.0|       2.0|         0.0| 0.0|0.0|           0.0|   1.0|\n",
      "|      0.0|      3.0|           1.0|       0.0|         1.0| 0.0|1.0|           0.0|   1.0|\n",
      "|      0.0|      2.0|           0.0|       2.0|         0.0| 0.0|0.0|           0.0|   1.0|\n",
      "|      0.0|      1.0|           0.0|       2.0|         0.0| 1.0|0.0|           0.0|   1.0|\n",
      "|      3.0|      2.0|           0.0|       0.0|         0.0| 2.0|0.0|           8.0|   1.0|\n",
      "|      0.0|      2.0|           1.0|       3.0|         2.0| 0.0|1.0|           0.0|   0.0|\n",
      "|      0.0|      6.0|           1.0|       4.0|         1.0| 1.0|0.0|           0.0|   0.0|\n",
      "|      0.0|      4.0|           0.0|       1.0|         0.0| 2.0|0.0|           2.0|   1.0|\n",
      "|      0.0|      8.0|           0.0|       8.0|         0.0| 3.0|0.0|           1.0|   0.0|\n",
      "|      1.0|      0.0|           1.0|      10.0|         2.0| 0.0|0.0|           0.0|   0.0|\n",
      "|      0.0|      0.0|           1.0|       6.0|         3.0| 0.0|0.0|           0.0|   0.0|\n",
      "|      0.0|      5.0|           0.0|       4.0|         0.0| 0.0|0.0|           0.0|   0.0|\n",
      "|      1.0|      3.0|           2.0|       2.0|         3.0| 0.0|1.0|           0.0|   1.0|\n",
      "+---------+---------+--------------+----------+------------+----+---+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(dfnumeric.select(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"income\")\n",
    "      .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oneHotEncodeColumns(df,cols):\n",
    "    tempdf = df\n",
    "    for col in cols:\n",
    "        onehotenc = OneHotEncoder(inputCol=col,outputCol=col+\"-onehot\")\n",
    "        tempdf = onehotenc.transform(tempdf).drop(col)\n",
    "        tempdf = tempdf.withColumnRenamed(col+\"-onehot\",col)\n",
    "    return tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- sex: double (nullable = true)\n",
      " |-- income: double (nullable = true)\n",
      " |-- native_country: vector (nullable = true)\n",
      " |-- relationship: vector (nullable = true)\n",
      " |-- marital_status: vector (nullable = true)\n",
      " |-- race: vector (nullable = true)\n",
      " |-- workclass: vector (nullable = true)\n",
      " |-- education: vector (nullable = true)\n",
      " |-- occupation: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot = oneHotEncodeColumns(dfnumeric,{\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"native_country\"})\n",
    "dfhot.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+--------------+---------------+-------------+-------------+---------------+\n",
      "|    workclass|      education|marital_status|     occupation| relationship|         race| native_country|\n",
      "+-------------+---------------+--------------+---------------+-------------+-------------+---------------+\n",
      "|(7,[3],[1.0])| (15,[2],[1.0])| (6,[1],[1.0])| (14,[3],[1.0])|(5,[1],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[1],[1.0])| (15,[2],[1.0])| (6,[0],[1.0])| (14,[2],[1.0])|(5,[0],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[0],[1.0])| (6,[2],[1.0])| (14,[9],[1.0])|(5,[1],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[5],[1.0])| (6,[0],[1.0])| (14,[9],[1.0])|(5,[0],[1.0])|(4,[1],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[2],[1.0])| (6,[0],[1.0])| (14,[0],[1.0])|(5,[4],[1.0])|(4,[1],[1.0])| (41,[9],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[3],[1.0])| (6,[0],[1.0])| (14,[2],[1.0])|(5,[4],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])|(15,[10],[1.0])| (6,[5],[1.0])| (14,[5],[1.0])|(5,[1],[1.0])|(4,[1],[1.0])|(41,[11],[1.0])|\n",
      "|(7,[1],[1.0])| (15,[0],[1.0])| (6,[0],[1.0])| (14,[2],[1.0])|(5,[0],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[3],[1.0])| (6,[1],[1.0])| (14,[0],[1.0])|(5,[1],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[2],[1.0])| (6,[0],[1.0])| (14,[2],[1.0])|(5,[0],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[1],[1.0])| (6,[0],[1.0])| (14,[2],[1.0])|(5,[0],[1.0])|(4,[1],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[3],[1.0])| (15,[2],[1.0])| (6,[0],[1.0])| (14,[0],[1.0])|(5,[0],[1.0])|(4,[2],[1.0])| (41,[8],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[2],[1.0])| (6,[1],[1.0])| (14,[3],[1.0])|(5,[2],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[6],[1.0])| (6,[1],[1.0])| (14,[4],[1.0])|(5,[1],[1.0])|(4,[1],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[4],[1.0])| (6,[0],[1.0])| (14,[1],[1.0])|(5,[0],[1.0])|(4,[2],[1.0])| (41,[2],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[8],[1.0])| (6,[0],[1.0])| (14,[8],[1.0])|(5,[0],[1.0])|(4,[3],[1.0])| (41,[1],[1.0])|\n",
      "|(7,[1],[1.0])| (15,[0],[1.0])| (6,[1],[1.0])|(14,[10],[1.0])|(5,[2],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[0],[1.0])| (6,[1],[1.0])| (14,[6],[1.0])|(5,[3],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[0],[1.0])| (15,[5],[1.0])| (6,[0],[1.0])| (14,[4],[1.0])|(5,[0],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "|(7,[1],[1.0])| (15,[3],[1.0])| (6,[2],[1.0])| (14,[2],[1.0])|(5,[3],[1.0])|(4,[0],[1.0])| (41,[0],[1.0])|\n",
      "+-------------+---------------+--------------+---------------+-------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.select(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"native_country\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- sex: double (nullable = true)\n",
      " |-- income: double (nullable = true)\n",
      " |-- native_country: vector (nullable = true)\n",
      " |-- relationship: vector (nullable = true)\n",
      " |-- marital_status: vector (nullable = true)\n",
      " |-- race: vector (nullable = true)\n",
      " |-- workclass: vector (nullable = true)\n",
      " |-- education: vector (nullable = true)\n",
      " |-- occupation: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colList = dfhot.columns\n",
    "colList.remove('income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=colList,outputCol=\"features\")\n",
    "lpoints = vecAssembler.transform(dfhot).select(\"features\", \"income\").withColumnRenamed(\"income\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|capital_gain|count|\n",
      "+------------+-----+\n",
      "|     15024.0|  347|\n",
      "|      2202.0|   16|\n",
      "|      2977.0|    8|\n",
      "|     41310.0|    2|\n",
      "|      4508.0|   12|\n",
      "|      4101.0|   20|\n",
      "|      3411.0|   24|\n",
      "|     25236.0|   11|\n",
      "|      2961.0|    3|\n",
      "|      2936.0|    3|\n",
      "|      1409.0|    7|\n",
      "|      2009.0|    3|\n",
      "|      2329.0|    6|\n",
      "|      4787.0|   23|\n",
      "|      2829.0|   31|\n",
      "|      2354.0|   11|\n",
      "|      1151.0|    8|\n",
      "|      4687.0|    3|\n",
      "|      2463.0|   11|\n",
      "|      5455.0|   11|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.select('capital_gain').groupBy('capital_gain').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.0)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
